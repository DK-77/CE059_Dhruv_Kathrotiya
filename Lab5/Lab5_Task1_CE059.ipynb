{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5_Task1_CE059.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DK-77/CE059_Dhruv_Kathrotiya/blob/main/Lab5/Lab5_Task1_CE059.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8qjf0lkEvJQ",
        "outputId": "52161743-5336-46ce-b2f3-d43ebd119b0f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hb9Xt-GEx5P"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAVzTEutVkmi"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "# Targets (apples)\n",
        "# only for apples\n",
        "targets = np.array([[56], [81], [119], [22], [103], \n",
        "                    [56], [81], [119], [22], [103], \n",
        "                    [56], [81], [119], [22], [103]], dtype='float32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBGDucS2Vmbn",
        "outputId": "fa33fcfb-2129-4376-f511-29dbac4274e5"
      },
      "source": [
        "m = np.mean(inputs,0)\n",
        "print(\"mean :- \",m)\n",
        "std_dev = np.std(inputs, 0)\n",
        "print(\"\\n\\nstandard deviation :- \",std_dev)\n",
        "#normalizing the input\n",
        "x = (inputs-m) / std_dev\n",
        "x = np.hstack((np.ones((targets.size,1)),x))\n",
        "print(\"\\n\\nx \",x)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean :-  [84.4 85.6 54.4]\n",
            "\n",
            "\n",
            "standard deviation :-  [12.059851 30.388155 12.499599]\n",
            "\n",
            "\n",
            "x  [[ 1.         -0.94528544 -0.61208057 -0.91202933]\n",
            " [ 1.          0.54727036  0.07897819  0.7680245 ]\n",
            " [ 1.          0.21559127  1.59272587  0.28800911]\n",
            " [ 1.          1.45938778 -1.40186191 -1.39204478]\n",
            " [ 1.         -1.27696455  0.34223866  1.24803984]\n",
            " [ 1.         -0.94528544 -0.61208057 -0.91202933]\n",
            " [ 1.          0.54727036  0.07897819  0.7680245 ]\n",
            " [ 1.          0.21559127  1.59272587  0.28800911]\n",
            " [ 1.          1.45938778 -1.40186191 -1.39204478]\n",
            " [ 1.         -1.27696455  0.34223866  1.24803984]\n",
            " [ 1.         -0.94528544 -0.61208057 -0.91202933]\n",
            " [ 1.          0.54727036  0.07897819  0.7680245 ]\n",
            " [ 1.          0.21559127  1.59272587  0.28800911]\n",
            " [ 1.          1.45938778 -1.40186191 -1.39204478]\n",
            " [ 1.         -1.27696455  0.34223866  1.24803984]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFZ4HhHIXzly"
      },
      "source": [
        "Linear Regression Model (from scratch)\n",
        "\n",
        "The weights and biases can also be represented as matrices, initialized with random values. The first row of w and the first element of b are use to predict the first target variable i.e. yield for apples, and similarly the second for oranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-i6eF15VqPv",
        "outputId": "3670e1cc-55f5-416c-843e-f7ea1a332528"
      },
      "source": [
        "# Weights and biases\n",
        "rg = np.random.default_rng(59)\n",
        "w = rg.random((1, 4))\n",
        "b = rg.random()\n",
        "base = []\n",
        "for i in range(15):\n",
        "  base.append([b])\n",
        "print(w)\n",
        "print(base)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.58774716 0.82606617 0.11694378 0.37742961]]\n",
            "[[0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373], [0.18626235014329373]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i7Dg_lJVsMo"
      },
      "source": [
        "# MSE loss function\n",
        "def mse_loss(actual, predicted):\n",
        "    diff = actual - predicted\n",
        "    return np.sum(diff * diff) / diff.size"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P9sipdeVu2Q",
        "outputId": "c64a409a-b1f1-4abc-936f-5a18d91e474b"
      },
      "source": [
        "# Define the model\n",
        "def predict(x,w):\n",
        "    return (x @ w.T) + base\n",
        "\n",
        "# Compute error\n",
        "preds = predict(x,w)\n",
        "cost_initial = mse_loss(preds, targets)\n",
        "print(\"before regression cost is : \", cost_initial)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before regression cost is :  6871.207292664606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4x7cKoBV4qR"
      },
      "source": [
        "def gradient_descent(X, y, w, learning_rate, epochs):\n",
        "    history = np.zeros((epochs, 1))\n",
        "    for i in range(epochs):\n",
        "        h = predict(X, w)\n",
        "        diff = h - y\n",
        "        delta = (learning_rate / targets.size) * (X.T@diff)\n",
        "        new_w = w - delta.T\n",
        "        w = new_w\n",
        "        history[i] = mse_loss(h, y)\n",
        "        print(\"loss {} iteration {}\".format(history[i],i))\n",
        "    return (history, w)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alfGK4DDWFFo",
        "outputId": "ebb4a77c-7480-4f1a-a98c-987bb0a1fc89"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epochs = 250\n",
        "learning_rate = 0.01\n",
        "\n",
        "initial_cost = mse_loss(predict(x, w),targets)\n",
        "\n",
        "print(\"Initial cost is: \", initial_cost, \"\\n\")\n",
        "\n",
        "(history, optimal_params) = gradient_descent(x, targets, w, learning_rate, epochs)\n",
        "\n",
        "print(\"Optimal parameters are: \\n\", optimal_params, \"\\n\")\n",
        "\n",
        "print(\"Final cost is: \", history[-1])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial cost is:  6871.207292664606 \n",
            "\n",
            "loss [6871.20729266] iteration 0\n",
            "loss [6714.3457288] iteration 1\n",
            "loss [6561.4234966] iteration 2\n",
            "loss [6412.32982145] iteration 3\n",
            "loss [6266.95740892] iteration 4\n",
            "loss [6125.20232537] iteration 5\n",
            "loss [5986.96388277] iteration 6\n",
            "loss [5852.14452786] iteration 7\n",
            "loss [5720.6497352] iteration 8\n",
            "loss [5592.38790418] iteration 9\n",
            "loss [5467.27025976] iteration 10\n",
            "loss [5345.21075676] iteration 11\n",
            "loss [5226.12598764] iteration 12\n",
            "loss [5109.93509358] iteration 13\n",
            "loss [4996.55967881] iteration 14\n",
            "loss [4885.92372796] iteration 15\n",
            "loss [4777.95352641] iteration 16\n",
            "loss [4672.57758348] iteration 17\n",
            "loss [4569.72655843] iteration 18\n",
            "loss [4469.33318898] iteration 19\n",
            "loss [4371.33222249] iteration 20\n",
            "loss [4275.66034956] iteration 21\n",
            "loss [4182.25613998] iteration 22\n",
            "loss [4091.05998091] iteration 23\n",
            "loss [4002.01401738] iteration 24\n",
            "loss [3915.06209473] iteration 25\n",
            "loss [3830.14970322] iteration 26\n",
            "loss [3747.22392448] iteration 27\n",
            "loss [3666.23337994] iteration 28\n",
            "loss [3587.12818102] iteration 29\n",
            "loss [3509.85988104] iteration 30\n",
            "loss [3434.38142888] iteration 31\n",
            "loss [3360.64712421] iteration 32\n",
            "loss [3288.61257427] iteration 33\n",
            "loss [3218.2346522] iteration 34\n",
            "loss [3149.47145678] iteration 35\n",
            "loss [3082.28227356] iteration 36\n",
            "loss [3016.62753735] iteration 37\n",
            "loss [2952.46879601] iteration 38\n",
            "loss [2889.76867546] iteration 39\n",
            "loss [2828.49084592] iteration 40\n",
            "loss [2768.59998925] iteration 41\n",
            "loss [2710.06176752] iteration 42\n",
            "loss [2652.84279249] iteration 43\n",
            "loss [2596.91059631] iteration 44\n",
            "loss [2542.23360306] iteration 45\n",
            "loss [2488.78110131] iteration 46\n",
            "loss [2436.52321767] iteration 47\n",
            "loss [2385.43089112] iteration 48\n",
            "loss [2335.4758483] iteration 49\n",
            "loss [2286.63057954] iteration 50\n",
            "loss [2238.8683158] iteration 51\n",
            "loss [2192.16300627] iteration 52\n",
            "loss [2146.48929677] iteration 53\n",
            "loss [2101.8225089] iteration 54\n",
            "loss [2058.1386198] iteration 55\n",
            "loss [2015.41424266] iteration 56\n",
            "loss [1973.62660779] iteration 57\n",
            "loss [1932.75354441] iteration 58\n",
            "loss [1892.77346296] iteration 59\n",
            "loss [1853.66533799] iteration 60\n",
            "loss [1815.40869167] iteration 61\n",
            "loss [1777.98357778] iteration 62\n",
            "loss [1741.37056624] iteration 63\n",
            "loss [1705.55072813] iteration 64\n",
            "loss [1670.50562121] iteration 65\n",
            "loss [1636.2172759] iteration 66\n",
            "loss [1602.66818169] iteration 67\n",
            "loss [1569.84127402] iteration 68\n",
            "loss [1537.71992154] iteration 69\n",
            "loss [1506.28791382] iteration 70\n",
            "loss [1475.52944938] iteration 71\n",
            "loss [1445.42912422] iteration 72\n",
            "loss [1415.97192053] iteration 73\n",
            "loss [1387.14319596] iteration 74\n",
            "loss [1358.92867307] iteration 75\n",
            "loss [1331.31442916] iteration 76\n",
            "loss [1304.28688645] iteration 77\n",
            "loss [1277.83280252] iteration 78\n",
            "loss [1251.93926109] iteration 79\n",
            "loss [1226.593663] iteration 80\n",
            "loss [1201.78371758] iteration 81\n",
            "loss [1177.49743421] iteration 82\n",
            "loss [1153.72311414] iteration 83\n",
            "loss [1130.44934261] iteration 84\n",
            "loss [1107.66498114] iteration 85\n",
            "loss [1085.35916014] iteration 86\n",
            "loss [1063.52127163] iteration 87\n",
            "loss [1042.14096229] iteration 88\n",
            "loss [1021.20812663] iteration 89\n",
            "loss [1000.71290046] iteration 90\n",
            "loss [980.64565444] iteration 91\n",
            "loss [960.99698792] iteration 92\n",
            "loss [941.7577229] iteration 93\n",
            "loss [922.91889819] iteration 94\n",
            "loss [904.47176379] iteration 95\n",
            "loss [886.4077753] iteration 96\n",
            "loss [868.71858867] iteration 97\n",
            "loss [851.39605494] iteration 98\n",
            "loss [834.43221527] iteration 99\n",
            "loss [817.819296] iteration 100\n",
            "loss [801.54970393] iteration 101\n",
            "loss [785.61602168] iteration 102\n",
            "loss [770.01100326] iteration 103\n",
            "loss [754.72756966] iteration 104\n",
            "loss [739.75880467] iteration 105\n",
            "loss [725.09795074] iteration 106\n",
            "loss [710.73840498] iteration 107\n",
            "loss [696.67371533] iteration 108\n",
            "loss [682.89757673] iteration 109\n",
            "loss [669.40382749] iteration 110\n",
            "loss [656.18644573] iteration 111\n",
            "loss [643.23954588] iteration 112\n",
            "loss [630.55737533] iteration 113\n",
            "loss [618.13431119] iteration 114\n",
            "loss [605.96485703] iteration 115\n",
            "loss [594.04363984] iteration 116\n",
            "loss [582.36540702] iteration 117\n",
            "loss [570.92502338] iteration 118\n",
            "loss [559.71746838] iteration 119\n",
            "loss [548.73783329] iteration 120\n",
            "loss [537.98131849] iteration 121\n",
            "loss [527.44323088] iteration 122\n",
            "loss [517.11898131] iteration 123\n",
            "loss [507.00408206] iteration 124\n",
            "loss [497.09414445] iteration 125\n",
            "loss [487.38487648] iteration 126\n",
            "loss [477.87208051] iteration 127\n",
            "loss [468.55165104] iteration 128\n",
            "loss [459.41957253] iteration 129\n",
            "loss [450.47191727] iteration 130\n",
            "loss [441.70484335] iteration 131\n",
            "loss [433.11459258] iteration 132\n",
            "loss [424.6974886] iteration 133\n",
            "loss [416.44993495] iteration 134\n",
            "loss [408.36841316] iteration 135\n",
            "loss [400.44948103] iteration 136\n",
            "loss [392.68977078] iteration 137\n",
            "loss [385.08598737] iteration 138\n",
            "loss [377.63490683] iteration 139\n",
            "loss [370.33337458] iteration 140\n",
            "loss [363.1783039] iteration 141\n",
            "loss [356.16667433] iteration 142\n",
            "loss [349.29553016] iteration 143\n",
            "loss [342.56197897] iteration 144\n",
            "loss [335.9631902] iteration 145\n",
            "loss [329.49639369] iteration 146\n",
            "loss [323.15887839] iteration 147\n",
            "loss [316.94799096] iteration 148\n",
            "loss [310.86113451] iteration 149\n",
            "loss [304.89576729] iteration 150\n",
            "loss [299.04940149] iteration 151\n",
            "loss [293.319602] iteration 152\n",
            "loss [287.70398527] iteration 153\n",
            "loss [282.20021811] iteration 154\n",
            "loss [276.80601659] iteration 155\n",
            "loss [271.51914495] iteration 156\n",
            "loss [266.33741454] iteration 157\n",
            "loss [261.25868275] iteration 158\n",
            "loss [256.28085198] iteration 159\n",
            "loss [251.40186871] iteration 160\n",
            "loss [246.61972247] iteration 161\n",
            "loss [241.93244489] iteration 162\n",
            "loss [237.33810883] iteration 163\n",
            "loss [232.83482742] iteration 164\n",
            "loss [228.42075321] iteration 165\n",
            "loss [224.09407728] iteration 166\n",
            "loss [219.85302844] iteration 167\n",
            "loss [215.69587238] iteration 168\n",
            "loss [211.62091086] iteration 169\n",
            "loss [207.62648097] iteration 170\n",
            "loss [203.71095431] iteration 171\n",
            "loss [199.87273627] iteration 172\n",
            "loss [196.11026531] iteration 173\n",
            "loss [192.42201223] iteration 174\n",
            "loss [188.80647946] iteration 175\n",
            "loss [185.26220043] iteration 176\n",
            "loss [181.78773885] iteration 177\n",
            "loss [178.38168807] iteration 178\n",
            "loss [175.04267048] iteration 179\n",
            "loss [171.76933685] iteration 180\n",
            "loss [168.56036575] iteration 181\n",
            "loss [165.41446292] iteration 182\n",
            "loss [162.33036074] iteration 183\n",
            "loss [159.30681763] iteration 184\n",
            "loss [156.34261751] iteration 185\n",
            "loss [153.43656924] iteration 186\n",
            "loss [150.58750611] iteration 187\n",
            "loss [147.79428534] iteration 188\n",
            "loss [145.05578751] iteration 189\n",
            "loss [142.37091615] iteration 190\n",
            "loss [139.73859717] iteration 191\n",
            "loss [137.15777847] iteration 192\n",
            "loss [134.62742941] iteration 193\n",
            "loss [132.14654041] iteration 194\n",
            "loss [129.71412247] iteration 195\n",
            "loss [127.32920674] iteration 196\n",
            "loss [124.99084413] iteration 197\n",
            "loss [122.69810488] iteration 198\n",
            "loss [120.45007813] iteration 199\n",
            "loss [118.24587156] iteration 200\n",
            "loss [116.08461098] iteration 201\n",
            "loss [113.96543997] iteration 202\n",
            "loss [111.8875195] iteration 203\n",
            "loss [109.85002755] iteration 204\n",
            "loss [107.8521588] iteration 205\n",
            "loss [105.89312424] iteration 206\n",
            "loss [103.97215084] iteration 207\n",
            "loss [102.08848126] iteration 208\n",
            "loss [100.24137345] iteration 209\n",
            "loss [98.43010041] iteration 210\n",
            "loss [96.65394981] iteration 211\n",
            "loss [94.91222375] iteration 212\n",
            "loss [93.20423841] iteration 213\n",
            "loss [91.52932379] iteration 214\n",
            "loss [89.8868234] iteration 215\n",
            "loss [88.27609403] iteration 216\n",
            "loss [86.69650541] iteration 217\n",
            "loss [85.14743999] iteration 218\n",
            "loss [83.62829267] iteration 219\n",
            "loss [82.13847053] iteration 220\n",
            "loss [80.67739258] iteration 221\n",
            "loss [79.24448955] iteration 222\n",
            "loss [77.83920361] iteration 223\n",
            "loss [76.46098814] iteration 224\n",
            "loss [75.10930752] iteration 225\n",
            "loss [73.7836369] iteration 226\n",
            "loss [72.48346195] iteration 227\n",
            "loss [71.20827869] iteration 228\n",
            "loss [69.95759325] iteration 229\n",
            "loss [68.73092168] iteration 230\n",
            "loss [67.52778972] iteration 231\n",
            "loss [66.34773263] iteration 232\n",
            "loss [65.19029499] iteration 233\n",
            "loss [64.05503049] iteration 234\n",
            "loss [62.94150179] iteration 235\n",
            "loss [61.84928028] iteration 236\n",
            "loss [60.77794594] iteration 237\n",
            "loss [59.72708717] iteration 238\n",
            "loss [58.69630058] iteration 239\n",
            "loss [57.68519086] iteration 240\n",
            "loss [56.69337061] iteration 241\n",
            "loss [55.72046016] iteration 242\n",
            "loss [54.76608744] iteration 243\n",
            "loss [53.82988781] iteration 244\n",
            "loss [52.91150391] iteration 245\n",
            "loss [52.0105855] iteration 246\n",
            "loss [51.12678935] iteration 247\n",
            "loss [50.25977907] iteration 248\n",
            "loss [49.40922499] iteration 249\n",
            "Optimal parameters are: \n",
            " [[69.89981887 -4.76226059 21.46703583 12.42130558]] \n",
            "\n",
            "Final cost is:  [49.40922499]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaC_aMBTWa7J"
      },
      "source": [
        "Adjust Weights using Gradints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ej4gzOMdWdJ4",
        "outputId": "2e86e112-0df2-4ecc-d3e7-686c0ebb7afb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(range(len(history)), history, 'g')\n",
        "\n",
        "plt.title(\"Convergence Graph of Cost Function\")\n",
        "plt.xlabel(\"Number of Iterations\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6joEDqO9Wg0X",
        "outputId": "f0351767-dd4d-4c65-9c9e-c8294a6e5c53"
      },
      "source": [
        "# Calculate error\n",
        "preds = predict(x, optimal_params)\n",
        "cost_final = mse_loss(preds, targets)\n",
        "# Print predictions\n",
        "print(\"Prediction:\\n\",preds)\n",
        "# Comparing predicted with targets\n",
        "print(\"Targets:\\n\", targets)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:\n",
            " [[ 50.11962625]\n",
            " [ 78.71513183]\n",
            " [106.82793194]\n",
            " [ 15.75126292]\n",
            " [ 99.01645308]\n",
            " [ 50.11962625]\n",
            " [ 78.71513183]\n",
            " [106.82793194]\n",
            " [ 15.75126292]\n",
            " [ 99.01645308]\n",
            " [ 50.11962625]\n",
            " [ 78.71513183]\n",
            " [106.82793194]\n",
            " [ 15.75126292]\n",
            " [ 99.01645308]]\n",
            "Targets:\n",
            " [[ 56.]\n",
            " [ 81.]\n",
            " [119.]\n",
            " [ 22.]\n",
            " [103.]\n",
            " [ 56.]\n",
            " [ 81.]\n",
            " [119.]\n",
            " [ 22.]\n",
            " [103.]\n",
            " [ 56.]\n",
            " [ 81.]\n",
            " [119.]\n",
            " [ 22.]\n",
            " [103.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQbG_aRXWinR",
        "outputId": "4c49d661-a0df-42ba-b0fa-d31565bbd963"
      },
      "source": [
        "print(\"Cost after linear regression: \", cost_final)\n",
        "print(\"Cost reduction : {} %\".format(((cost_initial- cost_final) / cost_initial) * 100))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after linear regression:  48.5748040069338\n",
            "Cost reduction : 99.29306740521727 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckV4Md2dZ5s3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}